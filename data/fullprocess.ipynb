{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the outline of the full preprocess on the data to get it ready for the model:\n",
    "1. standartize the data from (processing.py)  \n",
    "2. remove nan heavy trials (nanProcessing.py)\n",
    "3. interpolate the missing values (nanProcessing.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing.processData import process\n",
    "from nanHandling.nanProcessing import nanPercentages\n",
    "from nanHandling.nanProcessing import nan_to_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install alive-progress\n",
    "from alive_progress import alive_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = pd.read_pickle('../../fulldata/processed/trainingData.pkl')\n",
    "trainingSubjectInfo = pd.read_pickle('../../fulldata/processed/trainingSubjectInfo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingData = pd.read_pickle('../../fulldata/processed/testingData.pkl')\n",
    "testingSubjectInfo = pd.read_pickle('../../fulldata/processed/testingSubjectInfo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepProcess(dataframe, subjectframe, nancut = .4):\n",
    "    print('Copying dataframes...')\n",
    "    dataframe = dataframe.copy()\n",
    "    subjectframe = subjectframe.copy()\n",
    "    # 1. Process data\n",
    "    print('Processing data...')\n",
    "    dataframe = process(dataframe)\n",
    "    # 2. Remove NaN-heavy trials\n",
    "    print('Removing NaN-heavy trials')\n",
    "    percentnan = nanPercentages(dataframe)\n",
    "    subjectframe['percentNanWhole'] = percentnan['whole']\n",
    "    subjectframe['percentNanMax'] = percentnan['max']\n",
    "    nancutSubjectInfo = subjectframe.query('percentNanWhole < .4 and percentNanMax < .6')\n",
    "    nancutData = dataframe.loc[nancutSubjectInfo.index]\n",
    "    nancutData.sort_values(by=['time'], inplace=True)\n",
    "    # 3. Interpolate NaNs\n",
    "    print('Interpolating NaNs...')\n",
    "    sts = nancutData.index.unique().to_list()\n",
    "    with alive_bar(len(sts), force_tty=True) as bar:\n",
    "        for st in sts:\n",
    "            nancutData.loc[[st], ['right_pupil', 'left_pupil', 'right_gaze_x', 'right_gaze_y', 'left_gaze_x', 'left_gaze_y']] = nancutData.loc[[st], ['right_pupil', 'left_pupil', 'right_gaze_x', 'right_gaze_y', 'left_gaze_x', 'left_gaze_y']].apply(nan_to_interp)\n",
    "            bar()\n",
    "    return nancutData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying dataframes...\n",
      "Processing data...\n",
      "Removing NaN-heavy trials\n",
      "Interpolating NaNs...\n",
      "|▋⚠︎                                      | (!) 61/3843 [2%] in 1:18.7 (0.77/s)  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_y_train \u001b[39m=\u001b[39m deepProcess(trainingData, trainingSubjectInfo)\n\u001b[1;32m      2\u001b[0m X_y_train\u001b[39m.\u001b[39mto_pickle(\u001b[39m'\u001b[39m\u001b[39m../../fulldata/processed/X_y_train.pkl\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m, in \u001b[0;36mdeepProcess\u001b[0;34m(dataframe, subjectframe, nancut)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mwith\u001b[39;00m alive_bar(\u001b[39mlen\u001b[39m(sts), force_tty\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m bar:\n\u001b[1;32m     20\u001b[0m     \u001b[39mfor\u001b[39;00m st \u001b[39min\u001b[39;00m sts:\n\u001b[0;32m---> 21\u001b[0m         nancutData\u001b[39m.\u001b[39mloc[[st], [\u001b[39m'\u001b[39m\u001b[39mright_pupil\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mleft_pupil\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mright_gaze_x\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mright_gaze_y\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mleft_gaze_x\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mleft_gaze_y\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m nancutData\u001b[39m.\u001b[39;49mloc[[st], [\u001b[39m'\u001b[39;49m\u001b[39mright_pupil\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mleft_pupil\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mright_gaze_x\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mright_gaze_y\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mleft_gaze_x\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mleft_gaze_y\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39mapply(nan_to_interp)\n\u001b[1;32m     22\u001b[0m         bar()\n\u001b[1;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m nancutData\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1287\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[39m# ugly hack for GH #836\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m-> 1287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_multi_take(tup)\n\u001b[1;32m   1289\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1238\u001b[0m, in \u001b[0;36m_LocIndexer._multi_take\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1223\u001b[0m \u001b[39mCreate the indexers for the passed tuple of keys, and\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[39mexecutes the take operation. This allows the take operation to be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[39mvalues: same type as the object being indexed\u001b[39;00m\n\u001b[1;32m   1236\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m \u001b[39m# GH 836\u001b[39;00m\n\u001b[0;32m-> 1238\u001b[0m d \u001b[39m=\u001b[39m {\n\u001b[1;32m   1239\u001b[0m     axis: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1240\u001b[0m     \u001b[39mfor\u001b[39;00m (key, axis) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tup, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_AXIS_ORDERS)\n\u001b[1;32m   1241\u001b[0m }\n\u001b[1;32m   1242\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(d, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1239\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1223\u001b[0m \u001b[39mCreate the indexers for the passed tuple of keys, and\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[39mexecutes the take operation. This allows the take operation to be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[39mvalues: same type as the object being indexed\u001b[39;00m\n\u001b[1;32m   1236\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m \u001b[39m# GH 836\u001b[39;00m\n\u001b[1;32m   1238\u001b[0m d \u001b[39m=\u001b[39m {\n\u001b[0;32m-> 1239\u001b[0m     axis: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1240\u001b[0m     \u001b[39mfor\u001b[39;00m (key, axis) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tup, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_AXIS_ORDERS)\n\u001b[1;32m   1241\u001b[0m }\n\u001b[1;32m   1242\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(d, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1459\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1460\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1462\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1464\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py:5874\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5872\u001b[0m     keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex(keyarr)[\u001b[39m0\u001b[39m]\n\u001b[1;32m   5873\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 5874\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_non_unique(keyarr)\n\u001b[1;32m   5876\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5878\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py:4317\u001b[0m, in \u001b[0;36mIndex._reindex_non_unique\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   4313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   4314\u001b[0m     \u001b[39m# GH#13691\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[:\u001b[39m0\u001b[39m], np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp), \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 4317\u001b[0m indexer, missing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_indexer_non_unique(target)\n\u001b[1;32m   4318\u001b[0m check \u001b[39m=\u001b[39m indexer \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   4319\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer[check])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py:5835\u001b[0m, in \u001b[0;36mIndex.get_indexer_non_unique\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   5831\u001b[0m     \u001b[39m# Item \"IndexEngine\" of \"Union[IndexEngine, ExtensionEngine]\" has\u001b[39;00m\n\u001b[1;32m   5832\u001b[0m     \u001b[39m# no attribute \"_extract_level_codes\"\u001b[39;00m\n\u001b[1;32m   5833\u001b[0m     tgt_values \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39m_extract_level_codes(target)  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m-> 5835\u001b[0m indexer, missing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_indexer_non_unique(tgt_values)\n\u001b[1;32m   5836\u001b[0m \u001b[39mreturn\u001b[39;00m ensure_platform_int(indexer), ensure_platform_int(missing)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_y_train = deepProcess(trainingData, trainingSubjectInfo)\n",
    "X_y_train.to_pickle('../../fulldata/processed/X_y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_test = deepProcess(trainingData, trainingSubjectInfo)\n",
    "X_y_test.to_pickle('../../fulldata/processed/X_y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
